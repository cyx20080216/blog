<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>全连接神经网络浅析 - cyx20080216的小屋</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="cyx20080216"><meta name=description content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传"><meta name=generator content="Hugo 0.97.1 with theme even"><link rel=canonical href=https://cyx20080216.github.io/blog/post/fully-neural-network/><link rel=apple-touch-icon sizes=180x180 href=/blog/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=manifest href=/blog/manifest.json><link rel=mask-icon href=/blog/safari-pinned-tab.svg color=#5bbad5><link href=/blog/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="全连接神经网络浅析"><meta property="og:description" content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传"><meta property="og:type" content="article"><meta property="og:url" content="https://cyx20080216.github.io/blog/post/fully-neural-network/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-04-15T22:41:00+08:00"><meta property="article:modified_time" content="2022-04-17T21:24:00+08:00"><meta itemprop=name content="全连接神经网络浅析"><meta itemprop=description content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传"><meta itemprop=datePublished content="2022-04-15T22:41:00+08:00"><meta itemprop=dateModified content="2022-04-17T21:24:00+08:00"><meta itemprop=wordCount content="2198"><meta itemprop=keywords content="算法,机器学习,"><meta name=twitter:card content="summary"><meta name=twitter:title content="全连接神经网络浅析"><meta name=twitter:description content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/blog/ class=logo>cyx20080216的小屋</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/blog/><li class=mobile-menu-item>首页</li></a><a href=/blog/post/><li class=mobile-menu-item>历史</li></a><a href=/blog/tags/><li class=mobile-menu-item>标签</li></a><a href=/blog/categories/><li class=mobile-menu-item>分类</li></a><a href=/blog/abaut/><li class=mobile-menu-item>关于</li></a><a href=/blog/search/><li class=mobile-menu-item>🔍</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/blog/ class=logo>cyx20080216的小屋</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/blog/>首页</a></li><li class=menu-item><a class=menu-item-link href=/blog/post/>历史</a></li><li class=menu-item><a class=menu-item-link href=/blog/tags/>标签</a></li><li class=menu-item><a class=menu-item-link href=/blog/categories/>分类</a></li><li class=menu-item><a class=menu-item-link href=/blog/abaut/>关于</a></li><li class=menu-item><a class=menu-item-link href=/blog/search/>🔍</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>全连接神经网络浅析</h1><div class=post-meta><span class=post-time>2022-04-15</span><div class=post-category><a href=/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div><span class=more-meta>约 2198 字</span>
<span class=more-meta>预计阅读 5 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#神经元>神经元</a></li><li><a href=#约定>约定</a></li><li><a href=#前向传播>前向传播</a></li><li><a href=#训练>训练</a></li><li><a href=#反向传播>反向传播</a></li><li><a href=#总结>总结</a></li><li><a href=#再谈训练>再谈训练</a></li><li><a href=#演示代码>演示代码</a></li></ul></nav></div></div><div class=post-content><p><img src=https://cyx20080216.github.io/blog/images/neural-network-structure.png alt=全连接神经网络简图></p><p>这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成</p><p>在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传播的完整推导过程</p><h1 id=神经元>神经元</h1><p>将一个神经元放大来看，大概是这样：</p><p><img src=https://cyx20080216.github.io/blog/images/neural-structure.png alt=神经元简图></p><p>其中， $w_i$ 是权重， $b$ 是偏置， $f(x)$ 是激活函数</p><p>激活函数有很多种，常用的有 Sigmoid, ReLU 等，但它们的目的都是为了增强网络的拟合能力，进行<strong>非线性的拟合</strong></p><p><strong>激活函数必须是非线性的</strong></p><p>令 $n$ 为输入数量， $x_i$ 为每个输入的值</p><p>在激活之前，它的输出为输入加权求和后的值。即 $q=\sum_{i=1}^nw_ix_i+b$</p><p>激活之后，它的输出为： $r=f_k(q)=f(\sum_{i=1}^nw_ix_i+b)$</p><p>请务必记牢这两个式子，后面会频繁地使用它们</p><h1 id=约定>约定</h1><p>网络层数（不包括输入层）： $T$</p><p>网络输入数量： $n_0$</p><p>第 $k$ 层神经元数量： $n_k$</p><p>第 $k$ 层的激活函数： $f_k(x)$</p><p>连接第 $k$ 层第 $i$ 个神经元与上一层第 $j$ 个神经元的权重： $w_{kij}$</p><p>第 $k$ 层第 $i$ 个神经元的偏置： $b_{ki}$</p><p>网络的第 $i$ 个输入： $r_{0i}$</p><p>第 $k$ 层第 $i$ 个神经元激活前的输出： $q_{ki}$</p><p>第 $k$ 层第 $i$ 个神经元激活后的输出： $r_{ki}$</p><h1 id=前向传播>前向传播</h1><p>之前，我们已经知道了每一个神经元的工作方法</p><p>那么这一步十分简单，用一样的方法即可</p><p>$$q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$$</p><p>$$r_{ki}=f_k(q_{ki})$$</p><p>最后一层神经元激活后的输出，就是整个神经网络的输出</p><h1 id=训练>训练</h1><p>到目前为止，我们还有一个很大的问题：参数从哪来？</p><p>类似于网络层数、神经元数量这些关于网络结构以及之后要说的训练过程的参数，我们称为<strong>超参数</strong></p><p>这些参数通常由网络设计者来设定</p><p>而权重和偏置，手动设定显然不现实。所以，我们通过让网络自己学习这些参数，这就是<strong>训练</strong></p><p>为了训练神经网络，首先要设计一个损失函数，用来评估模型的准确度</p><p>如 $L(x_1, x_2, &mldr; x_n, y_1, y_2, &mldr; y_n)=\sum_{i=1}^n(x_i-y_i)^2$ 就是一种常用的损失函数</p><p>我们令期望输出的第 $i$ 个值为 $y_i$</p><p>我们令损失值 $l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$</p><p>想要找到最合适的参数，就是找到 $l$ 的低谷</p><p>我们可以通过一些方法求出 $\dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}$ 和 $\dfrac{\mathrm{d}l}{\mathrm{d}w_{bi}}$</p><p>求出了微分，我们就能够知道如何调整参数才能让 $l$ 尽可能快地减小</p><p>这就是<strong>梯度下降法</strong></p><p>我们使用<strong>优化器</strong>这一概念来描述调整的方法，我们令其为 $O(w, d, \eta)$</p><p>最简单的一种就是 $O(w, d, \eta)=w-\eta d$</p><p>其中的 $\eta$ 指学习率，这也是个超参数</p><p>通常情况下，太高的学习率会导致损失值不稳定，太低会导致学习过慢</p><p>一般，我们可以取 $\eta=0.01$</p><p>这样一来，只需不断使</p><p>$$w_{kij}\gets O(w_{kij}, \dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}, \eta)$$</p><p>$$b_{ki}\gets O(b_{ki}, \dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}, \eta)$$</p><p>就可以得到较优的参数</p><h1 id=反向传播>反向传播</h1><p>现在，我们来说说如何求出 $\dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}$ 和 $\dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}$ ，这也是最难的一部分</p><p><strong>高能预警，请有一定的微分基础后再往下读</strong></p><p>首先，根据 $q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$ ，我们得出</p><p>$$
\begin{aligned}
\dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}&=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}\cdot\dfrac{\mathrm{d}q_{ki}}{\mathrm{d}w_{kij}}\
&=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}\cdot r_{{k-1}j}\
\end{aligned}
$$</p><p>$$
\begin{aligned}
\dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}&=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}\cdot\dfrac{\mathrm{d}q_{ki}}{\mathrm{d}b_{ki}}\
&=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}\
\end{aligned}
$$</p><p>$$
\begin{aligned}
\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}&=\sum_{j=1}^{n_{k+1}}\dfrac{\mathrm{d}l}{\mathrm{d}q_{{k+1}j}}\cdot\dfrac{\mathrm{d}q_{{k+1}j}}{\mathrm{d}r_{ki}}\cdot\dfrac{\mathrm{d}r_{ki}}{\mathrm{d}q_{ki}}\
&=\sum_{j=1}^{n_{k+1}}\dfrac{\mathrm{d}l}{\mathrm{d}q_{{k+1}j}}\cdot w_{{k+1}ji}\cdot f_k^{&rsquo;}(q_{ki})\
&=(\sum_{j=1}^{n_{k+1}}\dfrac{\mathrm{d}l}{\mathrm{d}q_{{k+1}j}}\cdot w_{{k+1}ji})\cdot f_k^{&rsquo;}(q_{ki})\
\end{aligned}
$$</p><p>根据 $l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$ ，可以得出</p><p>$$
\begin{aligned}
\dfrac{\mathrm{d}l}{\mathrm{d}q_{Ti}}&=\dfrac{\mathrm{d}l}{\mathrm{d}r_{Ti}}\cdot\dfrac{\mathrm{d}r_{Ti}}{\mathrm{d}q_{Ti}}\
&=\dfrac{\mathrm{d}l}{\mathrm{d}r_{Ti}}\cdot f_T^{&rsquo;}(q_{Ti})\
\end{aligned}
$$</p><p>得出了这几条公式，我们就能从后往前算出所有的 $\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}$ ，再用它们求出所有的 $\dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}$ 和 $\dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}$ ，用来进行梯度下降</p><h1 id=总结>总结</h1><p>总结起来，重要的公式无外乎这几个：</p><p>$$q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$$</p><p>$$r_{ki}=f_k(q_{ki})$$</p><p>$$l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$$</p><p>$$\dfrac{\mathrm{d}l}{\mathrm{d}q_{Ti}}=\dfrac{\mathrm{d}l}{\mathrm{d}r_{Ti}}\cdot f_T^{&rsquo;}(q_{Ti})$$</p><p>$$\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}=(\sum_{j=1}^{n_{k+1}}\dfrac{\mathrm{d}l}{\mathrm{d}q_{{k+1}j}}\cdot w_{{k+1}ji})\cdot f_k^{&rsquo;}(q_{ki})$$</p><p>$$\dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}\cdot r_{{k-1}j}$$</p><p>$$\dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}=\dfrac{\mathrm{d}l}{\mathrm{d}q_{ki}}$$</p><p>$$w_{kij}\gets O(w_{kij}, \dfrac{\mathrm{d}l}{\mathrm{d}w_{kij}}, \eta)$$</p><p>$$b_{ki}\gets O(b_{ki}, \dfrac{\mathrm{d}l}{\mathrm{d}b_{ki}}, \eta)$$</p><h1 id=再谈训练>再谈训练</h1><p>在训练一个模型时，需要将数据集分成两部分：训练集和测试集</p><p>测试集不能以任何形式参与训练，仅用于测试模型准确性</p><p>若模型在训练集上表现优异，但在测试集上表现不佳，可能是出现了<strong>过拟合</strong>，这时可以通过减少网络层数和增加训练集的数据量来解决</p><h1 id=演示代码>演示代码</h1><p>年代久远，风格不一致请见谅</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span><span class=lnt>289
</span><span class=lnt>290
</span><span class=lnt>291
</span><span class=lnt>292
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;vector&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;random&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;functional&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>class</span> <span class=nc>FeedforwardNeuralNetwork</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>FeedforwardNeuralNetwork</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>inNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>neuralNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>calculate</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>void</span> <span class=nf>train</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=k>class</span> <span class=nc>NeuralLayer</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>                <span class=n>NeuralLayer</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>weightForNextLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForNextLayer</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=kt>void</span> <span class=nf>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>weight</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>bias</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=n>activationFunction</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=n>activationFunctionDerivative</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>};</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>ans</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>void</span> <span class=nf>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>NeuralLayer</span><span class=o>&gt;</span> <span class=n>layer</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>FeedforwardNeuralNetwork</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>inNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>neuralNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>layer</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=n>inNum</span><span class=p>,</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>activationFunction</span><span class=p>,</span><span class=n>activationFunctionDerivative</span><span class=p>)</span><span class=o>:</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>),</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>activationFunction</span><span class=p>,</span><span class=n>activationFunctionDerivative</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>calculate</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//输出最终结果
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nf>forward</span><span class=p>(</span><span class=n>in</span><span class=p>).</span><span class=n>back</span><span class=p>().</span><span class=n>second</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>train</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>ans</span><span class=o>=</span><span class=n>forward</span><span class=p>(</span><span class=n>in</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>gradient</span><span class=o>=</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>,</span><span class=n>desiredOut</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>outForEachLayer</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>outForEachLayer</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>adjust</span><span class=p>(</span><span class=n>in</span><span class=p>,</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=n>gradient</span><span class=p>,</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>_activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>_activationFunctionDerivative</span><span class=p>)</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>activationFunction</span><span class=p>(</span><span class=n>_activationFunction</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>_activationFunctionDerivative</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>neuralNumForThisLayer</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>weight</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>());</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>neuralNumForLastLayer</span><span class=p>;</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>weight</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>].</span><span class=n>push_back</span><span class=p>((</span><span class=o>*</span><span class=n>randomNumberGeneration</span><span class=p>)()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>2.0</span><span class=o>-</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>bias</span><span class=p>.</span><span class=n>push_back</span><span class=p>((</span><span class=o>*</span><span class=n>randomNumberGeneration</span><span class=p>)()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>2.0</span><span class=o>-</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//前向传播
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span> <span class=c1>//激活前
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span><span class=c1>//激活后
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>outForLastLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>bias</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>activationFunction</span><span class=p>(</span><span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]));</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nf>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span><span class=n>out</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span>   <span class=c1>//计算输出层局部微分
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=p>(</span><span class=n>outForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>desiredOut</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>inForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>weightForNextLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForNextLayer</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//计算隐藏层局部微分
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>gradient</span><span class=p>[</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>gradientForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>gradient</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>gradient</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*=</span><span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>inForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>   <span class=c1>//调整参数
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>weight</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>-=</span><span class=n>learningRate</span><span class=o>*</span><span class=n>gradientForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>outForLastLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>bias</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>bias</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>-=</span><span class=n>learningRate</span><span class=o>*</span><span class=n>gradientForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>ans</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ans</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>forward</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=nl>in</span><span class=p>:</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>).</span><span class=n>second</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ans</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>ans</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>&gt;=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>--</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>i</span><span class=o>==</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl>            <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>,</span><span class=n>desiredOut</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span>
</span></span><span class=line><span class=cl>            <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=p>).</span><span class=n>weight</span><span class=p>,</span><span class=n>gradient</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>()</span><span class=o>-</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>j</span><span class=o>=</span><span class=n>gradient</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>&lt;</span><span class=n>j</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>,</span><span class=n>j</span><span class=o>--</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>swap</span><span class=p>(</span><span class=n>gradient</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span><span class=n>gradient</span><span class=p>[</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>layer</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>].</span><span class=n>adjust</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=nl>in</span><span class=p>:</span><span class=n>outForEachLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>),</span><span class=n>gradientForEachLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;math.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#define E 2.7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=kt>double</span> <span class=nf>Sigmoid</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=mf>1.0</span><span class=o>+</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>double</span> <span class=nf>SigmoidDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Sigmoid</span><span class=p>(</span><span class=n>a</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>Sigmoid</span><span class=p>(</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#undef E
</span></span></span><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;math.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#define E 2.7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=kt>double</span> <span class=nf>Tanh</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=n>a</span><span class=p>)</span><span class=o>-</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>))</span><span class=o>/</span><span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>double</span> <span class=nf>TanhDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=mf>4.0</span><span class=o>*</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>))</span><span class=o>/</span><span class=p>((</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=mf>1.0</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=mf>1.0</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#undef E
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=kt>double</span> <span class=nf>ReLU</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>a</span><span class=o>&gt;</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>double</span> <span class=nf>ReLUDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>a</span><span class=o>&gt;=</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mf>1.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#include</span><span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=kt>void</span> <span class=nf>printNetwork</span><span class=p>(</span><span class=k>const</span> <span class=n>FeedforwardNeuralNetwork</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Layer %u:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;    Node %u:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>j</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;        Weight:&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf &#34;</span><span class=p>,</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>k</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;        Bias:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>bias</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>train</span><span class=p>(</span><span class=n>FeedforwardNeuralNetwork</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>trainSet</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>roundNum</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>frequency</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Start train</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;=</span><span class=n>roundNum</span><span class=p>;</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>double</span> <span class=n>loss</span><span class=o>=</span><span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>network</span><span class=o>-&gt;</span><span class=n>train</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>,</span><span class=n>learningRate</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>(</span><span class=n>network</span><span class=o>-&gt;</span><span class=n>calculate</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>));</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span><span class=o>+=</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>%</span><span class=n>frequency</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;In:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Desired Out:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Out:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>/=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>%</span><span class=n>frequency</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Loss:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>loss</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=n>printNetwork</span><span class=p>(</span><span class=o>*</span><span class=n>network</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Finished train</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>test</span><span class=p>(</span><span class=n>FeedforwardNeuralNetwork</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>testSet</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Start test</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kt>double</span> <span class=n>loss</span><span class=o>=</span><span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>(</span><span class=n>network</span><span class=o>-&gt;</span><span class=n>calculate</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>+=</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;In:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Desired Out:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Out:[&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>/=</span><span class=n>testSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Loss:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>loss</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Finished test</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;ctime&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;random&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=n>randomNumberGeneration</span><span class=p>(</span><span class=n>time</span><span class=p>(</span><span class=k>nullptr</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=kt>unsigned</span> <span class=n>inNum</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=n>neuralNum</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>3</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>3</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>FeedforwardNeuralNetwork</span> <span class=n>network</span><span class=p>(</span><span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span> <span class=n>inNum</span><span class=p>,</span> <span class=n>neuralNum</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>bind</span><span class=p>(</span><span class=n>Sigmoid</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>placeholders</span><span class=o>::</span><span class=n>_1</span><span class=p>),</span> <span class=n>std</span><span class=o>::</span><span class=n>bind</span><span class=p>(</span><span class=n>SigmoidDerivative</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>placeholders</span><span class=o>::</span><span class=n>_1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>trainSet</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=mi>10000</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>trainSet</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span> <span class=n>out</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>testSet</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=mi>50</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>testSet</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span> <span class=n>out</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=p>(</span><span class=o>&amp;</span><span class=n>network</span><span class=p>,</span> <span class=n>trainSet</span><span class=p>,</span> <span class=mf>0.03</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>test</span><span class=p>(</span><span class=o>&amp;</span><span class=n>network</span><span class=p>,</span> <span class=n>testSet</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>cyx20080216</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2022-04-17</span></p><p class=copyright-item><span class=item-title>原始文档</span>
<span class=item-content><a class=link-to-markdown href=https://cyx20080216.github.io/blog/post/fully-neural-network/index.md target=_blank>查看本文 Markdown 版本 »</a></span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank>署名-非商业性使用-相同方式共享 4.0 国际</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/blog/tags/%E7%AE%97%E6%B3%95/>算法</a>
<a href=/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div><nav class=post-nav><a class=next href=/blog/post/linear-regression/><span class="next-text nav-default">线性回归</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=cyx20080216/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:cyx20080216@outlook.com class="iconfont icon-email" title=email></a>
<a href=https://github.com/cyx20080216 class="iconfont icon-github" title=github></a>
<a href=https://cyx20080216.github.io/blog/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2021 -
2022<span class=heart><i class="iconfont icon-heart"></i></span><span>cyx20080216</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/blog/js/main.min.64437849d125a2d603b3e71d6de5225d641a32d17168a58106e0b61852079683.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>