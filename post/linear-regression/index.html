<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>线性回归 - cyx20080216的小屋</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="cyx20080216"><meta name=description content="问题 有 $n$ 个点，坐标分别为 $(x_1,y_1)$ , $(x_2,y_2)$ &amp;hellip; $(x_n,y_n)$ 有一个函数，格式为 $f(x)=kx$ 有一个损失值，计算方式为 $l=\sum_{i=1}^n(f(x_i)-y_i)^2$ 如何找到一个使 $l$ 最小的 $k$ ？ 梯度下降 一个简单的方法是选择一个随"><meta name=generator content="Hugo 0.96.0 with theme even"><link rel=canonical href=https://cyx20080216.github.io/blog/post/linear-regression/><link rel=apple-touch-icon sizes=180x180 href=/blog/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=manifest href=/blog/manifest.json><link rel=mask-icon href=/blog/safari-pinned-tab.svg color=#5bbad5><link href=/blog/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="线性回归"><meta property="og:description" content="问题 有 $n$ 个点，坐标分别为 $(x_1,y_1)$ , $(x_2,y_2)$ &mldr; $(x_n,y_n)$ 有一个函数，格式为 $f(x)=kx$ 有一个损失值，计算方式为 $l=\sum_{i=1}^n(f(x_i)-y_i)^2$ 如何找到一个使 $l$ 最小的 $k$ ？ 梯度下降 一个简单的方法是选择一个随"><meta property="og:type" content="article"><meta property="og:url" content="https://cyx20080216.github.io/blog/post/linear-regression/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-04-14T10:49:00+08:00"><meta property="article:modified_time" content="2022-04-14T10:49:00+08:00"><meta itemprop=name content="线性回归"><meta itemprop=description content="问题 有 $n$ 个点，坐标分别为 $(x_1,y_1)$ , $(x_2,y_2)$ &mldr; $(x_n,y_n)$ 有一个函数，格式为 $f(x)=kx$ 有一个损失值，计算方式为 $l=\sum_{i=1}^n(f(x_i)-y_i)^2$ 如何找到一个使 $l$ 最小的 $k$ ？ 梯度下降 一个简单的方法是选择一个随"><meta itemprop=datePublished content="2022-04-14T10:49:00+08:00"><meta itemprop=dateModified content="2022-04-14T10:49:00+08:00"><meta itemprop=wordCount content="276"><meta itemprop=keywords content="算法,机器学习,"><meta name=twitter:card content="summary"><meta name=twitter:title content="线性回归"><meta name=twitter:description content="问题 有 $n$ 个点，坐标分别为 $(x_1,y_1)$ , $(x_2,y_2)$ &mldr; $(x_n,y_n)$ 有一个函数，格式为 $f(x)=kx$ 有一个损失值，计算方式为 $l=\sum_{i=1}^n(f(x_i)-y_i)^2$ 如何找到一个使 $l$ 最小的 $k$ ？ 梯度下降 一个简单的方法是选择一个随"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/blog/ class=logo>cyx20080216的小屋</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/blog/><li class=mobile-menu-item>首页</li></a><a href=/blog/post/><li class=mobile-menu-item>历史</li></a><a href=/blog/tags/><li class=mobile-menu-item>标签</li></a><a href=/blog/categories/><li class=mobile-menu-item>分类</li></a><a href=/blog/abaut/><li class=mobile-menu-item>关于</li></a><a href=/blog/search/><li class=mobile-menu-item>🔍</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/blog/ class=logo>cyx20080216的小屋</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/blog/>首页</a></li><li class=menu-item><a class=menu-item-link href=/blog/post/>历史</a></li><li class=menu-item><a class=menu-item-link href=/blog/tags/>标签</a></li><li class=menu-item><a class=menu-item-link href=/blog/categories/>分类</a></li><li class=menu-item><a class=menu-item-link href=/blog/abaut/>关于</a></li><li class=menu-item><a class=menu-item-link href=/blog/search/>🔍</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>线性回归</h1><div class=post-meta><span class=post-time>2022-04-14</span><div class=post-category><a href=/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div><span class=more-meta>约 276 字</span>
<span class=more-meta>预计阅读 1 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#问题>问题</a></li><li><a href=#梯度下降>梯度下降</a></li><li><a href=#计算梯度>计算梯度</a></li><li><a href=#进阶>进阶</a></li></ul></nav></div></div><div class=post-content><h1 id=问题>问题</h1><p>有 $n$ 个点，坐标分别为 $(x_1,y_1)$ , $(x_2,y_2)$ &mldr; $(x_n,y_n)$</p><p>有一个函数，格式为 $f(x)=kx$</p><p>有一个损失值，计算方式为 $l=\sum_{i=1}^n(f(x_i)-y_i)^2$</p><p>如何找到一个使 $l$ 最小的 $k$ ？</p><h1 id=梯度下降>梯度下降</h1><p>一个简单的方法是选择一个随机的 $k$ ，然后不断改变 $k$ 使得 $l$ 降低</p><p>为了加快这一过程，可以利用梯度（也就是微分）来计算应该改变多少</p><p>我们设定一个<strong>超参数</strong>：<strong>学习率</strong> $\eta$</p><p>当学习率较大时，收敛速度会快，但是不稳定</p><p>当学习率较小时，收敛速度会慢，但是稳定</p><p>通常取 $\eta=0.01$</p><p>每次让 $k$ 移动 $-\frac{dl}{dk}\eta$</p><p>最后就可以得到较优的 $k$</p><h1 id=计算梯度>计算梯度</h1><p>这一步只需要简单的微分知识，可以得到 $\frac{dl}{dk}=\sum_{i=1}^n2x_i(f(x_i)-y_i)$</p><h1 id=进阶>进阶</h1><p>如果 $f(x)=kx+b$ ，就有了两个参数，但做法依然类似，不过是多处理一个参数</p><p>每次让 $k$ 移动 $-\frac{dl}{dk}\eta$</p><p>每次让 $b$ 移动 $-\frac{dl}{db}\eta$</p><p>$\frac{dl}{dk}=\sum_{i=1}^n2x_i(f(x_i)-y_i)$</p><p>$\frac{dl}{db}=\sum_{i=1}^n2(f(x_i)-y_i)$</p><p>这样便可以得到较优的 $k$ 和 $b$</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>cyx20080216</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2022-04-14</span></p><p class=copyright-item><span class=item-title>原始文档</span>
<span class=item-content><a class=link-to-markdown href=https://cyx20080216.github.io/blog/post/linear-regression/index.md target=_blank>查看本文 Markdown 版本 »</a></span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank>署名-非商业性使用-相同方式共享 4.0 国际</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/blog/tags/%E7%AE%97%E6%B3%95/>算法</a>
<a href=/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div><nav class=post-nav><a class=next href=/blog/post/how-to-set-up-personal-blog/><span class="next-text nav-default">如何利用Hugo,Fuse,Utterances,Github Pages,Github Actions搭建一个支持Marldown语法，搜索，评论，自动化部署，在线编辑的个人博客</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=cyx20080216/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:cyx20080216@outlook.com class="iconfont icon-email" title=email></a>
<a href=https://github.com/cyx20080216 class="iconfont icon-github" title=github></a>
<a href=https://cyx20080216.github.io/blog/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2021 -
2022<span class=heart><i class="iconfont icon-heart"></i></span><span>cyx20080216</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/blog/js/main.min.64437849d125a2d603b3e71d6de5225d641a32d17168a58106e0b61852079683.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>